{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "from skimage.filters import threshold_local\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import random as rng\n",
    "from matplotlib import pyplot as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_coefficients(p1: tuple, p2: tuple):\n",
    "  x1, y1 = p1\n",
    "  x2, y2 = p2\n",
    "\n",
    "  a = y1 - y2\n",
    "  b = x2 - x1\n",
    "  c = x1*y2 - x2*y1\n",
    "\n",
    "  return (a,b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection_points(coeff_1: tuple, coeff_2: tuple):\n",
    "  a1, b1, c1 = coeff_1\n",
    "  a2, b2, c2 = coeff_2\n",
    "\n",
    "  x = 0 \n",
    "  y = 0\n",
    "\n",
    "  det = a1 * b2 - a2 * b1\n",
    "\n",
    "  x_num = b1 * c2 - b2 * c1\n",
    "\n",
    "  y_num = c1 * a2 - c2 * a1\n",
    "\n",
    "  # lines are approximately parallel \n",
    "  if det > -0.5 and det < 0.5:\n",
    "    return None\n",
    "  \n",
    "\n",
    "  if det != 0:\n",
    "    x = x_num / det\n",
    "    y = y_num / det\n",
    "    return (x, y)\n",
    "  \n",
    "  return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_points(p1: tuple, p2: tuple):\n",
    "  x1, y1 = p1\n",
    "  x2, y2, = p2\n",
    "  distance = sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "  return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_similar_corners(c1: tuple, c2: tuple): \n",
    "  return True if distance_between_points(c1, c2) < 100 else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_similar_corners(all_corners):\n",
    "  corners = []\n",
    "  # get one corner\n",
    "  for i in range(len(all_corners)): \n",
    "    # check with all other corners\n",
    "    similar_corner = False\n",
    "    for j in range(len(all_corners)): \n",
    "      # if we have checked all corners upto this one then break\n",
    "      if i == j:\n",
    "        break\n",
    "      # if corner is similar to any of the previous corners then we do not add this corner\n",
    "      if are_similar_corners(all_corners[i], all_corners[j]): \n",
    "        similar_corner = True\n",
    "        break\n",
    "    if not similar_corner:\n",
    "      corners.append(all_corners[i])\n",
    "      \n",
    "  return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_possible_corners(coefficients, row_size, col_size): \n",
    "  all_corners = []\n",
    "\n",
    "  # for every combination of coeffs get the intersection points\n",
    "  for i in range(len(coefficients)):\n",
    "    for j in range(i, len(coefficients)):\n",
    "      if(i != j): \n",
    "      \n",
    "        int_point = get_intersection_points(coefficients[i], coefficients[j])\n",
    "        if int_point != None: \n",
    "          x, y = int_point\n",
    "          # coords should be within the image boundaries\n",
    "          if x > 0 and y > 0 and x < col_size and y < row_size:\n",
    "            all_corners.append(int_point)\n",
    "            \n",
    "  return all_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(elem):\n",
    "    return cv2.arcLength(elem, closed=True)\n",
    "    \n",
    "def get_corners(grayscale: cv2.Mat, output: cv2.Mat):\n",
    "  convex_hull_mask = np.zeros((grayscale.shape[0], grayscale.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "  convex_hull_mask_grayscale = cv2.cvtColor(convex_hull_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Find contours\n",
    "  contours, _ = cv2.findContours(grayscale, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "  # get the largest contour by sorting the contours wrt arcLength\n",
    "  contours = sorted(contours, key=sort_contours, reverse=True)[:1]\n",
    "\n",
    "  # convex hull object\n",
    "  hull_list = []\n",
    "  hull = cv2.convexHull(contours[-1], True)\n",
    "  hull_list.append(hull)\n",
    "\n",
    "  cv2.drawContours(convex_hull_mask_grayscale, hull_list, -1, (255,0,0), 2, 8)\n",
    "\n",
    "  # cv2.imshow('Convex Hull Mask', convex_hull_mask_grayscale)\n",
    "  # cv2.waitKey(10)\n",
    "\n",
    "  # # rho: The resolution parameter rho in pixels.\n",
    "  # # theta: The resolution of the parameter \\theta in radians.\n",
    "  # # threshold: The minimum number of intersecting points to detecta line.\n",
    "\n",
    "  lines = cv2.HoughLinesP(image = convex_hull_mask_grayscale, rho = 1, theta = np.pi / 180, minLineLength=200, maxLineGap=0, threshold=40)\n",
    "\n",
    "  # draw all houghlines\n",
    "  if lines is not None:\n",
    "    for line in lines:\n",
    "      l = line[0]\n",
    "      cv2.line(output, (l[0], l[1]), (l[2], l[3]), (0,255,0), 2, cv2.LINE_AA )\n",
    "  \n",
    "  # cv2.imshow('Lines', output) \n",
    "  # if at any point there are at least four lines then find the corners\n",
    "    \n",
    "  print(\"number of lines: \", len(lines))\n",
    "\n",
    "  if len(lines) >= 4:\n",
    "    coefficients = []\n",
    "    for line in lines:\n",
    "      l = line[0]\n",
    "      coefficients.append(get_line_coefficients((l[0], l[1]), (l[2], l[3])))\n",
    "  \n",
    "\n",
    "    rows, cols = grayscale.shape\n",
    "\n",
    "    # get all the corners from lines\n",
    "    all_corners = get_all_possible_corners(coefficients, rows, cols)\n",
    "\n",
    "    print(\"all corners found: \", len(all_corners), all_corners)\n",
    "\n",
    "    print(\"------------------------------------------------------\")\n",
    "\n",
    "    # remove corners that are similar to one corner\n",
    "    corners = remove_similar_corners(all_corners)\n",
    "\n",
    "    print(\"final corners found: \", len(corners), corners)\n",
    "\n",
    "    for x, y in corners:\n",
    "      cv2.circle(output, (int(x), int(y)),3, (0, 0, 255), 4)\n",
    "\n",
    "    # cv2.imshow('Corners', output)\n",
    "    # cv2.waitKey(10)\n",
    "    \n",
    "    return corners if len(corners) == 4 else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(points: list):\n",
    "\t# initialize a list of coordinates that will be ordered\n",
    "\t# such that the first entry in the list is the top-left,\n",
    "\t# the second entry is the top-right, the third is the\n",
    "\t# bottom-right, and the fourth is the bottom-left\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\tpts = np.array(points)\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\t# now, compute the difference between the points, the\n",
    "\t# top-right point will have the smallest difference,\n",
    "\t# whereas the bottom-left will have the largest difference\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "\t# obtain a consistent order of the points and unpack them\n",
    "\t# individually\n",
    "\trect = order_points(pts)\n",
    "\t# (tl, tr, br, bl) = rect\n",
    "\t# # compute the width of the new image, which will be the\n",
    "\t# # maximum distance between bottom-right and bottom-left\n",
    "\t# # x-coordiates or the top-right and top-left x-coordinates\n",
    "\t# widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\t# widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\t# maxWidth = max(int(widthA), int(widthB))\n",
    "\tmaxWidth = 480\n",
    "\n",
    "\t# compute the height of the new image, which will be the\n",
    "\t# maximum distance between the top-right and bottom-right\n",
    "\t# y-coordinates or the top-left and bottom-left y-coordinates\n",
    "\t# heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\t# heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\t# maxHeight = max(int(heightA), int(heightB))\n",
    "\tmaxHeight = 640\n",
    "\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\t# return the warped image\n",
    "\treturn warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_document(input_img):\n",
    "  # Convert image to gray and blur it\n",
    "  input_grey = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "  input_grey = cv2.GaussianBlur(input_grey, (3,3), 0)\n",
    "  # ret, input_grey = cv2.threshold(input_grey, 130, 200, cv2.THRESH_BINARY)\n",
    "\n",
    "  # cv2.imshow(\"BINARY\", input_grey)\n",
    "\n",
    "  img_copy = input_img.copy()\n",
    "\n",
    "  edges = cv2.Canny(input_grey, 83, 300)\n",
    "\n",
    "  # cv2.imshow('Canny', edges)\n",
    "  # cv2.waitKey(10)\n",
    "\n",
    "  corners = get_corners(edges, input_img)\n",
    "\n",
    "  if corners is None:\n",
    "    print(\"INVALID CORNERS\")\n",
    "  else: \n",
    "    print(\"FINAL CORNERS: \", corners)\n",
    "    # draw corner points on the image\n",
    "\n",
    "    # perspective_transform(corners)\n",
    "    warped_img = four_point_transform(img_copy, corners)\n",
    "    # cv2.imshow(\"warped img\", warped_img)\n",
    "    # cv2.waitKey(10)\n",
    "    return warped_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng.seed(12345)\n",
    "\n",
    "# # read and show the input image\n",
    "# img_path = 'images/document-aligned.jpeg'\n",
    "# input_img = cv2.imread(img_path)\n",
    "# warped_img = scan_document(input_img)\n",
    "\n",
    "# cv2.imshow(\"Corners\", input_img)\n",
    "\n",
    "# if warped_img is not None: \n",
    "#   cv2.imshow(\"Transformation\", warped_img)\n",
    "\n",
    "# cv2.waitKey(10)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('videos/document-video-compress.mp4')\n",
    " \n",
    " \n",
    "# Loop until the end of the video\n",
    "while (video.isOpened()):\n",
    " \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video.read()\n",
    "    # frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "    #                      interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    warped_img = scan_document(frame)\n",
    "    if warped_img is not None: \n",
    "        cv2.imshow(\"Warp\", warped_img)\n",
    " \n",
    "    # conversion of BGR to grayscale is necessary to apply this operation\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # # adaptive thresholding to use different threshold\n",
    "    # # values on different regions of the frame.\n",
    "    # Thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    " \n",
    "    # cv2.imshow('Threxsh', Thresh)\n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video capture object\n",
    "video.release()\n",
    "# Closes all the windows currently opened.\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scanner)",
   "language": "python",
   "name": "scanner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "489122fc7bb5d6816f8d543671f3551350096832bab9acc5add7d3bb06b4362e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
